{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4492ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e79469",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2477ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316678, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Duration_of_Visit</th>\n",
       "      <th>Holiday_Package</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Year</th>\n",
       "      <th>country</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>quarter</th>\n",
       "      <th>where_contact_lives</th>\n",
       "      <th>visits</th>\n",
       "      <th>nights</th>\n",
       "      <th>Amount_Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-15</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>1600.680374</td>\n",
       "      <td>11204.762616</td>\n",
       "      <td>1.103402e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-15</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Female</td>\n",
       "      <td>2009</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>1600.680374</td>\n",
       "      <td>11204.762616</td>\n",
       "      <td>1.125278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-24</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>3064.743058</td>\n",
       "      <td>20873.377956</td>\n",
       "      <td>1.622982e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-24</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Female</td>\n",
       "      <td>2009</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>2702.755561</td>\n",
       "      <td>12411.702616</td>\n",
       "      <td>1.164191e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-24</td>\n",
       "      <td>14-27 nights</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Female</td>\n",
       "      <td>2009</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>525.351507</td>\n",
       "      <td>7354.921102</td>\n",
       "      <td>7.633357e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Duration_of_Visit Holiday_Package     Sex  Year  country mode  \\\n",
       "0   0-15       4-13 nights     Independent    Male  2009  Austria  Air   \n",
       "1   0-15       4-13 nights     Independent  Female  2009  Austria  Air   \n",
       "2  16-24       4-13 nights     Independent    Male  2009  Austria  Air   \n",
       "3  16-24       4-13 nights     Independent  Female  2009  Austria  Air   \n",
       "4  16-24      14-27 nights     Independent  Female  2009  Austria  Air   \n",
       "\n",
       "   purpose  quarter where_contact_lives       visits        nights  \\\n",
       "0  Holiday  Jan-Mar        UK residents  1600.680374  11204.762616   \n",
       "1  Holiday  Jan-Mar        UK residents  1600.680374  11204.762616   \n",
       "2  Holiday  Jan-Mar        UK residents  3064.743058  20873.377956   \n",
       "3  Holiday  Jan-Mar        UK residents  2702.755561  12411.702616   \n",
       "4  Holiday  Jan-Mar        UK residents   525.351507   7354.921102   \n",
       "\n",
       "   Amount_Spent  \n",
       "0  1.103402e+06  \n",
       "1  1.125278e+06  \n",
       "2  1.622982e+06  \n",
       "3  1.164191e+06  \n",
       "4  7.633357e+05  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('cleaned_Travelpac_removed_outliers.xlsx', 'Sheet1')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b567a3",
   "metadata": {},
   "source": [
    "# Model to predict Amount spent\n",
    "### Splittin data into target and feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f7a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape (316678,)\n",
      "First Five sample dataset for labels\n",
      "features shape (316678, 12)\n",
      "0    1.103402e+06\n",
      "1    1.125278e+06\n",
      "2    1.622982e+06\n",
      "3    1.164191e+06\n",
      "4    7.633357e+05\n",
      "Name: Amount_Spent, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>country</th>\n",
       "      <th>Duration_of_Visit</th>\n",
       "      <th>Year</th>\n",
       "      <th>mode</th>\n",
       "      <th>purpose</th>\n",
       "      <th>quarter</th>\n",
       "      <th>where_contact_lives</th>\n",
       "      <th>visits</th>\n",
       "      <th>nights</th>\n",
       "      <th>Holiday_Package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-15</td>\n",
       "      <td>Male</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>2009</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>1600.680374</td>\n",
       "      <td>11204.762616</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>2009</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>1600.680374</td>\n",
       "      <td>11204.762616</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>2009</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>3064.743058</td>\n",
       "      <td>20873.377956</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Austria</td>\n",
       "      <td>4-13 nights</td>\n",
       "      <td>2009</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>2702.755561</td>\n",
       "      <td>12411.702616</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Austria</td>\n",
       "      <td>14-27 nights</td>\n",
       "      <td>2009</td>\n",
       "      <td>Air</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Jan-Mar</td>\n",
       "      <td>UK residents</td>\n",
       "      <td>525.351507</td>\n",
       "      <td>7354.921102</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age     Sex  country Duration_of_Visit  Year mode  purpose  quarter  \\\n",
       "0   0-15    Male  Austria       4-13 nights  2009  Air  Holiday  Jan-Mar   \n",
       "1   0-15  Female  Austria       4-13 nights  2009  Air  Holiday  Jan-Mar   \n",
       "2  16-24    Male  Austria       4-13 nights  2009  Air  Holiday  Jan-Mar   \n",
       "3  16-24  Female  Austria       4-13 nights  2009  Air  Holiday  Jan-Mar   \n",
       "4  16-24  Female  Austria      14-27 nights  2009  Air  Holiday  Jan-Mar   \n",
       "\n",
       "  where_contact_lives       visits        nights Holiday_Package  \n",
       "0        UK residents  1600.680374  11204.762616     Independent  \n",
       "1        UK residents  1600.680374  11204.762616     Independent  \n",
       "2        UK residents  3064.743058  20873.377956     Independent  \n",
       "3        UK residents  2702.755561  12411.702616     Independent  \n",
       "4        UK residents   525.351507   7354.921102     Independent  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target variable\n",
    "labels = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features = data[['Age','Sex','country','Duration_of_Visit','Year','mode',\n",
    "                     'purpose','quarter','where_contact_lives', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features.shape}')\n",
    "print(labels.head())\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421d1750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221674, 12)\n",
      "(95004, 12)\n",
      "(221674,)\n",
      "(95004,)\n"
     ]
    }
   ],
   "source": [
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44917456",
   "metadata": {},
   "source": [
    "##### Pre-processing categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bed23d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The shape of X_train_cat_encoded is: (221674, 90)\n",
      " The shape of X_test_cat_encoded is: (95004, 90)\n"
     ]
    }
   ],
   "source": [
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','Sex','country','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','where_contact_lives']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','Sex','country','Duration_of_Visit','mode',\n",
    "                                  'purpose','quarter','where_contact_lives']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f4c64",
   "metadata": {},
   "source": [
    "##### Normalize the continuos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad207c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visits</th>\n",
       "      <th>nights</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96106</th>\n",
       "      <td>0.413912</td>\n",
       "      <td>0.265616</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96625</th>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.135142</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134745</th>\n",
       "      <td>0.084941</td>\n",
       "      <td>0.026785</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82810</th>\n",
       "      <td>0.043506</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87092</th>\n",
       "      <td>0.103436</td>\n",
       "      <td>0.126274</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          visits    nights      Year\n",
       "96106   0.413912  0.265616  0.250000\n",
       "96625   0.021730  0.135142  0.250000\n",
       "134745  0.084941  0.026785  0.333333\n",
       "82810   0.043506  0.025480  0.166667\n",
       "87092   0.103436  0.126274  0.166667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68837a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visits</th>\n",
       "      <th>nights</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44145</th>\n",
       "      <td>0.086519</td>\n",
       "      <td>0.067653</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21792</th>\n",
       "      <td>0.212311</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120381</th>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310057</th>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.113076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269541</th>\n",
       "      <td>0.233586</td>\n",
       "      <td>0.169924</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          visits    nights      Year\n",
       "44145   0.086519  0.067653  0.083333\n",
       "21792   0.212311  0.017943  0.000000\n",
       "120381  0.043165  0.015846  0.333333\n",
       "310057  0.059404  0.113076  1.000000\n",
       "269541  0.233586  0.169924  0.750000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8de7d5",
   "metadata": {},
   "source": [
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f4e1b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221674, 93)\n",
      "(95004, 93)\n"
     ]
    }
   ],
   "source": [
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79dae5",
   "metadata": {},
   "source": [
    "##### Fitting linear regression model for Amount spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bac01a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57cca2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data , Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b918e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred =model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a08daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=model.score(test_data, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "409b488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_r2=r2_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5efef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error MAE, and Mean Squared Error MSE\n",
    "mae_lr = round(metrics.mean_absolute_error(Y_test, Y_pred), 4)\n",
    "mse_lr = round(metrics.mean_squared_error(Y_test, Y_pred), 4)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab984847",
   "metadata": {},
   "source": [
    "##### Fitting Random Forest Regression to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "741c62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import the regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    " # create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(train_data , Y_train ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a11742",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1=regressor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5563024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr =regressor.score(test_data , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7f815f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_r2=r2_score(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c10ab4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbf0da",
   "metadata": {},
   "source": [
    "##### Comparing the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e641da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models = pd.DataFrame(\n",
    "    {  'Model' : ['Multiple Linear Regression', 'Random Forest Regression'],\n",
    "        'r2_Score' : [lin_reg_r2, rfr_r2],\n",
    "        'MAE'  : [mae_lr, mae_rfr],\n",
    "        'MSE'  : [mse_lr, mse_rfr]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52852e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model  r2_Score            MAE           MSE\n",
      "0  Multiple Linear Regression  0.504365  602585.128800  8.159056e+11\n",
      "1    Random Forest Regression  0.564633  529740.591477  7.166924e+11\n"
     ]
    }
   ],
   "source": [
    "print(compare_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a411e9",
   "metadata": {},
   "source": [
    "- We can now see the score and error of our models and compare them. Score of Random forest Regression is greater then Linear regression and error is also less.Thus, Random forest Regression will be the right choice for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e92fcc",
   "metadata": {},
   "source": [
    "### Feature selection to make our Random forest Model better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1ef09",
   "metadata": {},
   "source": [
    "##### Calculate the pearson coefficient between Amount spent and other  continuos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3911e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfcb1eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5123343084018617, 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rel between Amount spent and nights\n",
    "Amount = data['Amount_Spent']\n",
    "nights = data['nights']\n",
    "corr = pearsonr(Amount , nights)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d32777f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5231494020402545, 0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rel between Amount spent and visits\n",
    "Amount = data['Amount_Spent']\n",
    "visits = data['visits']\n",
    "corr = pearsonr(Amount , visits)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52940dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08158186261723734, 0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rel between Amount spent and year\n",
    "Amount = data['Amount_Spent']\n",
    "year = data['Year']\n",
    "corr = pearsonr(Amount , year)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fac7d3",
   "metadata": {},
   "source": [
    "- Conclusion: A positive relationship exist between 'Amount spent and number of visits' and  'Amount spent and the number of  nights' and  'Year and the Amount spent'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802fd76",
   "metadata": {},
   "source": [
    "#### Calculate the relationship between the Amount spent and each of the categorical variable using covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b63fe",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc2cfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-15</th>\n",
       "      <th>16-24</th>\n",
       "      <th>25-34</th>\n",
       "      <th>35-44</th>\n",
       "      <th>45-54</th>\n",
       "      <th>55-64</th>\n",
       "      <th>65 &amp; over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0-15  16-24  25-34  35-44  45-54  55-64  65 & over\n",
       "0     1      0      0      0      0      0          0\n",
       "1     1      0      0      0      0      0          0\n",
       "2     0      1      0      0      0      0          0\n",
       "3     0      1      0      0      0      0          0\n",
       "4     0      1      0      0      0      0          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "age=pd.get_dummies(data['Age'])\n",
    "age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2e9c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Amount_Spent', '0-15', '16-24', '25-34', '35-44', '45-54', '55-64',\n",
      "       '65 & over'],\n",
      "      dtype='object')\n",
      "[[ 1.         -0.07084424 -0.05281637  0.01376273  0.02912662  0.03652231\n",
      "   0.01587742 -0.00645651]\n",
      " [-0.07084424  1.         -0.09806623 -0.12463462 -0.12228439 -0.11849331\n",
      "  -0.10383129 -0.08244782]\n",
      " [-0.05281637 -0.09806623  1.         -0.19213764 -0.18851451 -0.18267016\n",
      "  -0.16006707 -0.12710216]\n",
      " [ 0.01376273 -0.12463462 -0.19213764  1.         -0.23958741 -0.23215969\n",
      "  -0.20343291 -0.16153704]\n",
      " [ 0.02912662 -0.12228439 -0.18851451 -0.23958741  1.         -0.22778187\n",
      "  -0.19959679 -0.15849095]\n",
      " [ 0.03652231 -0.11849331 -0.18267016 -0.23215969 -0.22778187  1.\n",
      "  -0.19340887 -0.15357739]\n",
      " [ 0.01587742 -0.10383129 -0.16006707 -0.20343291 -0.19959679 -0.19340887\n",
      "   1.         -0.13457416]\n",
      " [-0.00645651 -0.08244782 -0.12710216 -0.16153704 -0.15849095 -0.15357739\n",
      "  -0.13457416  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Combine the continuos and categorical\n",
    "amount_age=pd.concat([Amount,age] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_age=amount_age.values\n",
    "corr_matrix=np.corrcoef(x_age.T)\n",
    "\n",
    "print(amount_age.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ef910",
   "metadata": {},
   "source": [
    "- Result: The amount spent has a weak negative correlation with ages 0-15 ,  16-24 and 65&over , While it has a weak positive correlation with the remaining ages, i.e ages 25-34 , 35-44 , 45-54 and 55-64. In other words , Amount spent is slightly increased if the individual is a working class , while it reduces with more non working class \n",
    "\n",
    "- Conclusion: Amount spent has a weak correlation with ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd046615",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31b64fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Female  Male\n",
       "0       0     1\n",
       "1       1     0\n",
       "2       0     1\n",
       "3       1     0\n",
       "4       1     0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "sex=pd.get_dummies(data['Sex'])\n",
    "sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67f142de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Amount_Spent', 'Female', 'Male'], dtype='object')\n",
      "[[ 1.         -0.04231468  0.04231468]\n",
      " [-0.04231468  1.         -1.        ]\n",
      " [ 0.04231468 -1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Combine the continuos and categorical\n",
    "amount_sex=pd.concat([Amount,sex] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_sex=amount_sex.values\n",
    "corr_matrix=np.corrcoef(x_sex.T)\n",
    "\n",
    "print(amount_sex.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd85a75",
   "metadata": {},
   "source": [
    "- Result: The Amount Spent has a weak negative relationship with the female sex, i.e for an increase in the female genger, \n",
    "    the amount spent decreases. Amount spent has a weak positive relationship eith the male gender\n",
    "- Conclusion: Gender do not have much relation ship with the amount spent, as the weak negative relationship with the \n",
    "    female seems to be balanced by a weak positive relationship with the male gender\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430f955",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e563aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Australia  Austria  Barbados  Belgium  Bulgaria  Canada  China - Hong Kong  \\\n",
      "0          0        1         0        0         0       0                  0   \n",
      "1          0        1         0        0         0       0                  0   \n",
      "2          0        1         0        0         0       0                  0   \n",
      "3          0        1         0        0         0       0                  0   \n",
      "4          0        1         0        0         0       0                  0   \n",
      "\n",
      "   China - Other  Croatia  Cyprus EU  ...  South Africa  Spain  Sri Lanka  \\\n",
      "0              0        0          0  ...             0      0          0   \n",
      "1              0        0          0  ...             0      0          0   \n",
      "2              0        0          0  ...             0      0          0   \n",
      "3              0        0          0  ...             0      0          0   \n",
      "4              0        0          0  ...             0      0          0   \n",
      "\n",
      "   Sweden  Switzerland  Thailand  Tunisia  Turkey  USA  United Arab Emirates  \n",
      "0       0            0         0        0       0    0                     0  \n",
      "1       0            0         0        0       0    0                     0  \n",
      "2       0            0         0        0       0    0                     0  \n",
      "3       0            0         0        0       0    0                     0  \n",
      "4       0            0         0        0       0    0                     0  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "Index(['Amount_Spent', 'Australia', 'Austria', 'Barbados', 'Belgium',\n",
      "       'Bulgaria', 'Canada', 'China - Hong Kong', 'China - Other', 'Croatia',\n",
      "       'Cyprus EU', 'Cyprus Non EU', 'Czech Republic', 'Denmark', 'Egypt',\n",
      "       'Estonia', 'Finland', 'France', 'Germany', 'Gibraltar', 'Greece',\n",
      "       'Hungary', 'Iceland', 'India', 'Irish Republic', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Latvia', 'Lithuania', 'Luxembourg', 'Malta',\n",
      "       'Mexico', 'Netherlands', 'New Zealand', 'Norway', 'Other Africa',\n",
      "       'Other Asia', 'Other Caribbean', 'Other Central & Sth.America',\n",
      "       'Other Europe', 'Other Middle East', 'Other North Africa',\n",
      "       'Other countries', 'Pakistan', 'Poland', 'Portugal', 'Romania',\n",
      "       'Russia', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sri Lanka',\n",
      "       'Sweden', 'Switzerland', 'Thailand', 'Tunisia', 'Turkey', 'USA',\n",
      "       'United Arab Emirates'],\n",
      "      dtype='object')\n",
      "[[ 1.          0.05653427 -0.01319667 ...  0.01846196  0.09790087\n",
      "   0.05819716]\n",
      " [ 0.05653427  1.         -0.02100236 ... -0.02007348 -0.0343307\n",
      "  -0.02206351]\n",
      " [-0.01319667 -0.02100236  1.         ... -0.01576909 -0.02696912\n",
      "  -0.0173324 ]\n",
      " ...\n",
      " [ 0.01846196 -0.02007348 -0.01576909 ...  1.         -0.02577635\n",
      "  -0.01656584]\n",
      " [ 0.09790087 -0.0343307  -0.02696912 ... -0.02577635  1.\n",
      "  -0.02833175]\n",
      " [ 0.05819716 -0.02206351 -0.0173324  ... -0.01656584 -0.02833175\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "country=pd.get_dummies(data['country'])\n",
    "print(country.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_country=pd.concat([Amount,country] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_country=amount_country.values\n",
    "corr_matrix=np.corrcoef(x_country.T)\n",
    "\n",
    "print(amount_country.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7ef21",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Duration_of_Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "400c9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1-3 nights  14-27 nights  28-90 nights  3-6 months  4-13 nights  \\\n",
      "0           0             0             0           0            1   \n",
      "1           0             0             0           0            1   \n",
      "2           0             0             0           0            1   \n",
      "3           0             0             0           0            1   \n",
      "4           0             1             0           0            0   \n",
      "\n",
      "   6 months-year  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "Index(['Amount_Spent', '1-3 nights', '14-27 nights', '28-90 nights',\n",
      "       '3-6 months', '4-13 nights', '6 months-year'],\n",
      "      dtype='object')\n",
      "[[ 1.         -0.20565728  0.11439228  0.03919663  0.02894774  0.07308083\n",
      "   0.01749842]\n",
      " [-0.20565728  1.         -0.31674222 -0.19508831 -0.0635727  -0.56101727\n",
      "  -0.02017483]\n",
      " [ 0.11439228 -0.31674222  1.         -0.14155538 -0.04612813 -0.40707214\n",
      "  -0.01463878]\n",
      " [ 0.03919663 -0.19508831 -0.14155538  1.         -0.0284113  -0.25072444\n",
      "  -0.00901634]\n",
      " [ 0.02894774 -0.0635727  -0.04612813 -0.0284113   1.         -0.08170264\n",
      "  -0.00293812]\n",
      " [ 0.07308083 -0.56101727 -0.40707214 -0.25072444 -0.08170264  1.\n",
      "  -0.02592837]\n",
      " [ 0.01749842 -0.02017483 -0.01463878 -0.00901634 -0.00293812 -0.02592837\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "Duration_of_Visit=pd.get_dummies(data['Duration_of_Visit'])\n",
    "print(Duration_of_Visit.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_duration=pd.concat([Amount,Duration_of_Visit] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_duration=amount_duration.values\n",
    "corr_matrix=np.corrcoef(x_duration.T)\n",
    "\n",
    "print(amount_duration.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38418ef0",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Mode of transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0249fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Air  Sea  Tunnel\n",
      "0    1    0       0\n",
      "1    1    0       0\n",
      "2    1    0       0\n",
      "3    1    0       0\n",
      "4    1    0       0\n",
      "Index(['Amount_Spent', 'Air', 'Sea', 'Tunnel'], dtype='object')\n",
      "[[ 1.         -0.20565728  0.11439228  0.03919663  0.02894774  0.07308083\n",
      "   0.01749842]\n",
      " [-0.20565728  1.         -0.31674222 -0.19508831 -0.0635727  -0.56101727\n",
      "  -0.02017483]\n",
      " [ 0.11439228 -0.31674222  1.         -0.14155538 -0.04612813 -0.40707214\n",
      "  -0.01463878]\n",
      " [ 0.03919663 -0.19508831 -0.14155538  1.         -0.0284113  -0.25072444\n",
      "  -0.00901634]\n",
      " [ 0.02894774 -0.0635727  -0.04612813 -0.0284113   1.         -0.08170264\n",
      "  -0.00293812]\n",
      " [ 0.07308083 -0.56101727 -0.40707214 -0.25072444 -0.08170264  1.\n",
      "  -0.02592837]\n",
      " [ 0.01749842 -0.02017483 -0.01463878 -0.00901634 -0.00293812 -0.02592837\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "mode=pd.get_dummies(data['mode'])\n",
    "print(mode.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_mode=pd.concat([Amount,mode] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_mode=amount_mode.values\n",
    "corr_matrix=np.corrcoef(x_duration.T)\n",
    "\n",
    "print(amount_mode.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5029f2b",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36066ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Business  Holiday  Miscellaneous  Study  VFR\n",
      "0         0        1              0      0    0\n",
      "1         0        1              0      0    0\n",
      "2         0        1              0      0    0\n",
      "3         0        1              0      0    0\n",
      "4         0        1              0      0    0\n",
      "Index(['Amount_Spent', 'Business', 'Holiday', 'Miscellaneous', 'Study', 'VFR'], dtype='object')\n",
      "[[ 1.          0.06096714  0.13103451 -0.0853006   0.0377893  -0.14731598]\n",
      " [ 0.06096714  1.         -0.37400804 -0.13047674 -0.05768164 -0.30256514]\n",
      " [ 0.13103451 -0.37400804  1.         -0.25180328 -0.11131812 -0.58391169]\n",
      " [-0.0853006  -0.13047674 -0.25180328  1.         -0.03883453 -0.2037039 ]\n",
      " [ 0.0377893  -0.05768164 -0.11131812 -0.03883453  1.         -0.09005417]\n",
      " [-0.14731598 -0.30256514 -0.58391169 -0.2037039  -0.09005417  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "purpose=pd.get_dummies(data['purpose'])\n",
    "print(purpose.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_purpose=pd.concat([Amount,purpose] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_purpose=amount_purpose.values\n",
    "corr_matrix=np.corrcoef(x_purpose.T)\n",
    "\n",
    "print(amount_purpose.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17fd6e",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eeb9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Apr-Jun  Jan-Mar  Jul-Sep  Oct-Dec\n",
      "0        0        1        0        0\n",
      "1        0        1        0        0\n",
      "2        0        1        0        0\n",
      "3        0        1        0        0\n",
      "4        0        1        0        0\n",
      "Index(['Amount_Spent', 'Apr-Jun', 'Jan-Mar', 'Jul-Sep', 'Oct-Dec'], dtype='object')\n",
      "[[ 1.         -0.00823116 -0.03298149  0.03732658  0.00224328]\n",
      " [-0.00823116  1.         -0.32188122 -0.35383009 -0.32234614]\n",
      " [-0.03298149 -0.32188122  1.         -0.34368802 -0.31310651]\n",
      " [ 0.03732658 -0.35383009 -0.34368802  1.         -0.34418444]\n",
      " [ 0.00224328 -0.32234614 -0.31310651 -0.34418444  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "quarter=pd.get_dummies(data['quarter'])\n",
    "print(quarter.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_quarter=pd.concat([Amount,quarter] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_quarter=amount_quarter.values\n",
    "corr_matrix=np.corrcoef(x_quarter.T)\n",
    "\n",
    "print(amount_quarter.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95b9ee",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and where contact lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d396597a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overseas residents  UK residents\n",
      "0                   0             1\n",
      "1                   0             1\n",
      "2                   0             1\n",
      "3                   0             1\n",
      "4                   0             1\n",
      "Index(['Amount_Spent', 'Overseas residents', 'UK residents'], dtype='object')\n",
      "[[ 1.         -0.09981649  0.09981649]\n",
      " [-0.09981649  1.         -1.        ]\n",
      " [ 0.09981649 -1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "where_contact_lives=pd.get_dummies(data['where_contact_lives'])\n",
    "print(where_contact_lives.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_where_contact_lives=pd.concat([Amount,where_contact_lives] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_where_contact_lives=amount_where_contact_lives.values\n",
    "corr_matrix=np.corrcoef(x_where_contact_lives.T)\n",
    "\n",
    "print(amount_where_contact_lives.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46653b9",
   "metadata": {},
   "source": [
    "##### Correlation Matrix between Amount and Holiday Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59fb24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Independent  Non-Independent\n",
      "0            1                0\n",
      "1            1                0\n",
      "2            1                0\n",
      "3            1                0\n",
      "4            1                0\n",
      "Index(['Amount_Spent', 'Independent', 'Non-Independent'], dtype='object')\n",
      "[[ 1.         -0.06117148  0.06117148]\n",
      " [-0.06117148  1.         -1.        ]\n",
      " [ 0.06117148 -1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data to dummy\n",
    "Holiday_Package=pd.get_dummies(data['Holiday_Package'])\n",
    "print(Holiday_Package.head())\n",
    "#Combine the continuos and categorical\n",
    "amount_Holiday_Package=pd.concat([Amount,Holiday_Package] ,axis=1)\n",
    "\n",
    "#Put in numpy array\n",
    "x_Holiday_Package=amount_Holiday_Package.values\n",
    "corr_matrix=np.corrcoef(x_Holiday_Package.T)\n",
    "\n",
    "print(amount_Holiday_Package.columns)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e515ee",
   "metadata": {},
   "source": [
    "### feature selection - Removing one of the continuos variable, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a1a6205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape (316678,)\n",
      "First Five sample dataset for labels\n",
      "features shape (316678, 11)\n",
      "0    1.103402e+06\n",
      "1    1.125278e+06\n",
      "2    1.622982e+06\n",
      "3    1.164191e+06\n",
      "4    7.633357e+05\n",
      "Name: Amount_Spent, dtype: float64\n",
      "(221674, 11)\n",
      "(95004, 11)\n",
      "(221674,)\n",
      "(95004,)\n",
      " The shape of X_train_cat_encoded is: (221674, 90)\n",
      " The shape of X_test_cat_encoded is: (95004, 90)\n",
      "(221674, 92)\n",
      "(95004, 92)\n"
     ]
    }
   ],
   "source": [
    "#target variable\n",
    "labels1 = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features1 = data[['Age','Sex','country','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','where_contact_lives', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels1.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features1.shape}')\n",
    "print(labels1.head())\n",
    "features1.head()\n",
    "\n",
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features1,\n",
    "                                                          labels1,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','Sex','country','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','where_contact_lives']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','Sex','country','Duration_of_Visit','mode',\n",
    "                                  'purpose','quarter','where_contact_lives']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")\n",
    "\n",
    "\n",
    "##### Pre-processing categorical variables\n",
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()\n",
    "\n",
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()\n",
    "\n",
    "\n",
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set\n",
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "##### Fitting Random Forest Regression to the dataset\n",
    " \n",
    " # create regressor object\n",
    "regressor1 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor1.fit(train_data , Y_train ) \n",
    "\n",
    "### Predicting with the model fit using test data\n",
    "Y_pred1=regressor1.predict(test_data)\n",
    "rfr =regressor1.score(test_data , Y_test)\n",
    "rfr_r2=r2_score(Y_test, Y_pred1)\n",
    "#### Mean square error\n",
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cd31a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R-Squared score , Mean Absolute Error  and Mean Square Error after removing Year\n",
      "\n",
      "\n",
      "                      Model  r2_Score            MAE           MSE\n",
      "0  Random Forest Regression  0.557524  534342.744479  7.283966e+11\n"
     ]
    }
   ],
   "source": [
    "print(f'Model R-Squared score , Mean Absolute Error  and Mean Square Error after removing Year')\n",
    "print('\\n')\n",
    "model_result = pd.DataFrame(\n",
    "    {  'Model' : ['Random Forest Regression'],\n",
    "        'r2_Score' : [ rfr_r2],\n",
    "        'MAE'  : [mae_rfr],\n",
    "        'MSE'  : [mse_rfr]\n",
    "    })\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ec887",
   "metadata": {},
   "source": [
    "### feature selection - Removing one of categorical variable,  Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bfca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable\n",
    "labels1 = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features1 = data[['Age','country','Duration_of_Visit','Year','mode',\n",
    "                     'purpose','quarter','where_contact_lives', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels1.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features1.shape}')\n",
    "print(labels1.head())\n",
    "features1.head()\n",
    "\n",
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features1,\n",
    "                                                          labels1,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','country','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','where_contact_lives']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','country','Duration_of_Visit','mode',\n",
    "                                  'purpose','quarter','where_contact_lives']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")\n",
    "\n",
    "\n",
    "##### Pre-processing categorical variables\n",
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()\n",
    "\n",
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()\n",
    "\n",
    "\n",
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set\n",
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "##### Fitting Random Forest Regression to the dataset\n",
    " \n",
    " # create regressor object\n",
    "regressor2 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor2.fit(train_data , Y_train ) \n",
    "\n",
    "### Predicting with the model fit using test data\n",
    "Y_pred1=regressor2.predict(test_data)\n",
    "rfr =regressor2.score(test_data , Y_test)\n",
    "rfr_r2=r2_score(Y_test, Y_pred1)\n",
    "#### Mean square error\n",
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ade519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model r Squared score , Mean Absolute Error  and Mean Square Error after removing Sex')\n",
    "model_result = pd.DataFrame(\n",
    "    {  'Model' : ['Random Forest Regression'],\n",
    "        'r2_Score' : [ rfr_r2],\n",
    "        'MAE'  : [mae_rfr],\n",
    "        'MSE'  : [mse_rfr]\n",
    "    })\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d8b82",
   "metadata": {},
   "source": [
    "### feature selection - Removing one of categorical variable,  purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be1070c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape (206222,)\n",
      "First Five sample dataset for labels\n",
      "features shape (206222, 11)\n",
      "0    1.103402e+06\n",
      "1    1.125278e+06\n",
      "2    1.622982e+06\n",
      "3    1.164191e+06\n",
      "4    7.633357e+05\n",
      "Name: Amount_Spent, dtype: float64\n",
      "(144355, 11)\n",
      "(61867, 11)\n",
      "(144355,)\n",
      "(61867,)\n",
      " The shape of X_train_cat_encoded is: (144355, 59)\n",
      " The shape of X_test_cat_encoded is: (61867, 59)\n",
      "(144355, 62)\n",
      "(61867, 62)\n"
     ]
    }
   ],
   "source": [
    "#target variable\n",
    "labels1 = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features1 = data[['Age','country','Duration_of_Visit','Year','mode',\n",
    "                     'Sex','quarter','where_contact_lives', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels1.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features1.shape}')\n",
    "print(labels1.head())\n",
    "features1.head()\n",
    "\n",
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features1,\n",
    "                                                          labels1,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','country','Duration_of_Visit','mode',\n",
    "                     'Sex','quarter','where_contact_lives']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','country','Duration_of_Visit','mode',\n",
    "                                  'Sex','quarter','where_contact_lives']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")\n",
    "\n",
    "\n",
    "##### Pre-processing categorical variables\n",
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()\n",
    "\n",
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()\n",
    "\n",
    "\n",
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set\n",
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "##### Fitting Random Forest Regression to the dataset\n",
    " \n",
    " # create regressor object\n",
    "regressor3 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor3.fit(train_data , Y_train ) \n",
    "\n",
    "### Predicting with the model fit using test data\n",
    "Y_pred1=regressor3.predict(test_data)\n",
    "rfr =regressor3.score(test_data , Y_test)\n",
    "rfr_r2=r2_score(Y_test, Y_pred1)\n",
    "#### Mean square error\n",
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "403ba306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model r squared score , Mean Absolute Error  and Mean Square Error after removing Purpose\n",
      "                      Model  r2_Score            MAE           MSE\n",
      "0  Random Forest Regression  0.510698  479732.107285  5.491521e+11\n"
     ]
    }
   ],
   "source": [
    "print(f'Model r squared score , Mean Absolute Error  and Mean Square Error after removing Purpose')\n",
    "model_result = pd.DataFrame(\n",
    "    {  'Model' : ['Random Forest Regression'],\n",
    "        'r2_Score' : [ rfr_r2],\n",
    "        'MAE'  : [mae_rfr],\n",
    "        'MSE'  : [mse_rfr]\n",
    "    })\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f14ac",
   "metadata": {},
   "source": [
    "### feature selection - Removing one of categorical variable, Where_contact_lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3456f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape (206222,)\n",
      "First Five sample dataset for labels\n",
      "features shape (206222, 11)\n",
      "0    1.103402e+06\n",
      "1    1.125278e+06\n",
      "2    1.622982e+06\n",
      "3    1.164191e+06\n",
      "4    7.633357e+05\n",
      "Name: Amount_Spent, dtype: float64\n",
      "(144355, 11)\n",
      "(61867, 11)\n",
      "(144355,)\n",
      "(61867,)\n",
      " The shape of X_train_cat_encoded is: (144355, 62)\n",
      " The shape of X_test_cat_encoded is: (61867, 62)\n",
      "(144355, 65)\n",
      "(61867, 65)\n"
     ]
    }
   ],
   "source": [
    "#target variable\n",
    "labels1 = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features1 = data[['Age','country','Duration_of_Visit','Year','mode',\n",
    "                     'purpose','quarter','Sex', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels1.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features1.shape}')\n",
    "print(labels1.head())\n",
    "features1.head()\n",
    "\n",
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features1,\n",
    "                                                          labels1,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','country','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','Sex']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','country','Duration_of_Visit','mode',\n",
    "                                  'purpose','quarter','Sex']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")\n",
    "\n",
    "\n",
    "##### Pre-processing categorical variables\n",
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()\n",
    "\n",
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()\n",
    "\n",
    "\n",
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set\n",
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "##### Fitting Random Forest Regression to the dataset\n",
    " \n",
    " # create regressor object\n",
    "regressor4 = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor4.fit(train_data , Y_train ) \n",
    "\n",
    "### Predicting with the model fit using test data\n",
    "Y_pred1=regressor4.predict(test_data)\n",
    "rfr =regressor4.score(test_data , Y_test)\n",
    "rfr_r2=r2_score(Y_test, Y_pred1)\n",
    "#### Mean square error\n",
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec29e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model r squared score , Mean Absolute Error  and Mean Square Error after removing the column \"Where contact lives\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12024/1134632790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model r squared score , Mean Absolute Error  and Mean Square Error after removing the column \"Where contact lives\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model_result = pd.DataFrame(\n\u001b[0m\u001b[0;32m      3\u001b[0m     {  'Model' : ['Random Forest Regression'],\n\u001b[0;32m      4\u001b[0m         \u001b[1;34m'r2_Score'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mrfr_r2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;34m'MAE'\u001b[0m  \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmae_rfr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Model r squared score , Mean Absolute Error  and Mean Square Error after removing the column \"Where contact lives\"')\n",
    "model_result = pd.DataFrame(\n",
    "    {  'Model' : ['Random Forest Regression'],\n",
    "        'r2_Score' : [ rfr_r2],\n",
    "        'MAE'  : [mae_rfr],\n",
    "        'MSE'  : [mse_rfr]\n",
    "    })\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c2d99",
   "metadata": {},
   "source": [
    "### feature selection - Removing one of categorical variable, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad742c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape (206222,)\n",
      "First Five sample dataset for labels\n",
      "features shape (206222, 11)\n",
      "0    1.103402e+06\n",
      "1    1.125278e+06\n",
      "2    1.622982e+06\n",
      "3    1.164191e+06\n",
      "4    7.633357e+05\n",
      "Name: Amount_Spent, dtype: float64\n",
      "(144355, 11)\n",
      "(61867, 11)\n",
      "(144355,)\n",
      "(61867,)\n",
      " The shape of X_train_cat_encoded is: (144355, 29)\n",
      " The shape of X_test_cat_encoded is: (61867, 29)\n",
      "(144355, 32)\n",
      "(61867, 32)\n"
     ]
    }
   ],
   "source": [
    "#target variable\n",
    "labels1 = data['Amount_Spent']\n",
    "#Include all other variables as feature variables\n",
    "features1 = data[['Age','where_contact_lives','Duration_of_Visit','Year','mode',\n",
    "                     'purpose','quarter','Sex', 'visits','nights', 'Holiday_Package']]\n",
    "\n",
    "print(f'label shape {labels1.shape}')\n",
    "print('First Five sample dataset for labels')\n",
    "print(f'features shape {features1.shape}')\n",
    "print(labels1.head())\n",
    "features1.head()\n",
    "\n",
    "# Split our data into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features1,\n",
    "                                                          labels1,\n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#For training data set \n",
    "X_train_cat = pd.DataFrame(X_train[['Age','where_contact_lives','Duration_of_Visit','mode',\n",
    "                     'purpose','quarter','Sex']])\n",
    "X_train_cat_encoded = pd.get_dummies(X_train_cat)\n",
    "print(f\" The shape of X_train_cat_encoded is: {X_train_cat_encoded.shape}\")\n",
    "\n",
    "#For testing data set\n",
    "X_test_cat = pd.DataFrame(X_test[['Age','where_contact_lives','Duration_of_Visit','mode',\n",
    "                                  'purpose','quarter','Sex']])\n",
    "X_test_cat_encoded = pd.get_dummies(X_test_cat)\n",
    "print(f\" The shape of X_test_cat_encoded is: {X_test_cat_encoded.shape}\")\n",
    "\n",
    "\n",
    "##### Pre-processing categorical variables\n",
    "#normalise the continuous variables (and Year) for training set \n",
    "X_train_cont = X_train[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_train_cont)\n",
    "X_train_cont_new = pd.DataFrame(x_scaled, columns=X_train_cont.columns, index=X_train_cont.index)\n",
    "X_train_cont_new.head()\n",
    "\n",
    "#normalise the continuous variables (and Year) for testing set \n",
    "X_test_cont = X_test[['visits','nights', 'Year']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X_test_cont)\n",
    "X_test_cont_new = pd.DataFrame(x_scaled, columns=X_test_cont.columns, index=X_test_cont.index)\n",
    "X_test_cont_new.head()\n",
    "\n",
    "\n",
    "##### Add DataFrame of continuous variables and categorical variables together for a complete training set\n",
    "train_data = X_train_cat_encoded.join(X_train_cont)\n",
    "#Do the same for test data\n",
    "test_data = X_test_cat_encoded.join(X_test_cont)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "##### Fitting Random Forest Regression to the dataset\n",
    " \n",
    " # create regressor object\n",
    "regressor5 = RandomForestRegressor(n_estimators = 200, random_state = 42)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor5.fit(train_data , Y_train ) \n",
    "\n",
    "### Predicting with the model fit using test data\n",
    "Y_pred1=regressor5.predict(test_data)\n",
    "rfr =regressor5.score(test_data , Y_test)\n",
    "rfr_r2=r2_score(Y_test, Y_pred1)\n",
    "#### Mean square error\n",
    "mae_rfr = metrics.mean_absolute_error(Y_test, Y_pred1)\n",
    "mse_rfr = metrics.mean_squared_error(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model r squared score , Mean Absolute Error  and Mean Square Error after removing the column \"country\"')\n",
    "model_result = pd.DataFrame(\n",
    "    {  'Model' : ['Random Forest Regression'],\n",
    "        'r2_Score' : [ rfr_r2],\n",
    "        'MAE'  : [mae_rfr],\n",
    "        'MSE'  : [mse_rfr]\n",
    "    })\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56113f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
